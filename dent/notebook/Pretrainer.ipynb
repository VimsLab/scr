{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Clone the repository"
      ],
      "metadata": {
        "id": "ZIcRCrPFG_5L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxmbcIR77THW",
        "outputId": "5115f06f-4131-421b-b8b4-f1e1e3cbfbc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'scr'...\n",
            "remote: Enumerating objects: 233, done.\u001b[K\n",
            "remote: Counting objects: 100% (233/233), done.\u001b[K\n",
            "remote: Compressing objects: 100% (207/207), done.\u001b[K\n",
            "remote: Total 233 (delta 29), reused 219 (delta 18), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (233/233), 20.93 MiB | 14.83 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b dev https://github.com/VimsLab/scr.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd scr/dent/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrnFuhMuIB_5",
        "outputId": "0226de01-188c-4ede-ef86-0490ffdd8b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/scr/dent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "OhlQ8TppHHN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "import torch\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import concurrent.futures\n",
        "import torch.nn.functional as F\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from torch.nn.parallel import DataParallel\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "from pretrain import *"
      ],
      "metadata": {
        "id": "kC07fYExG85a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrainer(rank, world_size, root, dataroot, phases=['sample', 'sample'], resume=False, save=False):\n",
        "    setup(rank, world_size)\n",
        "\n",
        "    num_epochs = 5\n",
        "    batch_size = 64 #// world_size\n",
        "    \n",
        "    tx_dict = tx()\n",
        "    train_loader, train_sampler = get_dataset(world_size, rank, dataroot, \n",
        "                                            phase=phases[0], lim=100, \n",
        "                                            transform=tx_dict['train'], \n",
        "                                            batch_size=batch_size, num_workers=2)\n",
        "    val_loader, val_sampler = get_dataset(world_size, rank, dataroot, \n",
        "                                        phase=phases[1], lim=50, \n",
        "                                        transform=tx_dict['val'], \n",
        "                                        batch_size=batch_size, num_workers=2)\n",
        "\n",
        "    # create model and optimizer\n",
        "    encoder = Encoder(hidden_dim=256, num_encoder_layers=6, nheads=8)\n",
        "    siamese_net = SiameseNetwork(encoder).to(rank)\n",
        "\n",
        "    # Wrap the model with DistributedDataParallel\n",
        "    siamese_net = DDP(siamese_net, device_ids=[rank], find_unused_parameters=False)\n",
        "\n",
        "    optimizer = torch.optim.Adam(siamese_net.parameters(), lr=0.001)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "\n",
        "    best_accuracy = 0\n",
        "    start_epoch = 0\n",
        "\n",
        "    if resume:\n",
        "        ckptfile = root + resume + '.pth'\n",
        "        ckpts = torch.load(ckptfile, map_location='cpu')\n",
        "        siamese_net.load_state_dict(ckpts['model_state_dict'])\n",
        "        optimizer.load_state_dict(ckpts['optimizer_state_dict'])\n",
        "        start_epoch = ckpts['epoch']+1\n",
        "        best_accuracy = ckpts['best_val_acc']\n",
        "\n",
        "        if rank == 0:\n",
        "            print('Resuming training from epoch {}. Loaded weights from {}. Last best accuracy was {}'\n",
        "                .format(start_epoch, ckptfile, best_accuracy))\n",
        "\n",
        "\n",
        "    # Train the network\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        train_sampler.set_epoch(epoch)\n",
        "        train_epoch(rank, siamese_net, optimizer, train_loader, epoch, num_epochs, running_loss=0)\n",
        "        \n",
        "        # Update the learning rate\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        if rank==0:\n",
        "            vloss, acc = validate(rank, siamese_net, val_loader)\n",
        "\n",
        "            if acc>=best_accuracy:\n",
        "                best_accuracy = acc\n",
        "                # save_path = root + 'epoch' + str(epoch) + 'best_pretrainer.pth'\n",
        "                save_path = root + 'best_pretrainer.pth'\n",
        "            else:\n",
        "                save_path = root + 'last_pretrainer.pth'\n",
        "            \n",
        "            checkpoint = {\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': siamese_net.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'best_val_acc': best_accuracy,\n",
        "                }\n",
        "            if save:\n",
        "              torch.save(checkpoint, save_path)\n",
        "              print('\\nSaved weights to', save_path)\n",
        "\n",
        "    # Clean up the process group\n",
        "    cleanup()            \n"
      ],
      "metadata": {
        "id": "XGyQpiFrS6Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = './'\n",
        "dataroot = '../sample_pkl/'\n",
        "world_size = 1\n",
        "pretrainer(0,world_size, root, dataroot, ['sample', 'sample'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxf96BJFGBg9",
        "outputId": "a2a39851-6515-408b-e707-1075b9c70f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading positive and negative pairs from pickled lists of sample\n",
            "sample dataset has 96 positive pairs and 1470 Negative pairs.\n",
            "Ratio of negative to positive samples = 15.3125\n",
            "\n",
            "Loading positive and negative pairs from pickled lists of sample\n",
            "sample dataset has 96 positive pairs and 1470 Negative pairs.\n",
            "Ratio of negative to positive samples = 15.3125\n",
            "\n",
            "                Device                 Epoch               GPU Mem                  Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                     0                   0/4                 8.56G              0.007569: 100%|██████████| 25/25 [00:23<00:00,  1.06it/s]          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                Device               Correct              Accuracy                  Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                     0             1470/1566                0.9387              0.007789: 100%|██████████| 25/25 [00:11<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                Device                 Epoch               GPU Mem                  Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                     0                   1/4                 9.83G              0.007817: 100%|██████████| 25/25 [00:21<00:00,  1.16it/s]          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                Device               Correct              Accuracy                  Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                     0             1470/1566                0.9387               0.00779: 100%|██████████| 25/25 [00:12<00:00,  1.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                Device                 Epoch               GPU Mem                  Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                     0                   2/4                 9.83G              0.007997: 100%|██████████| 25/25 [00:21<00:00,  1.15it/s]          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                Device               Correct              Accuracy                  Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                     0             1470/1566                0.9387              0.007801: 100%|██████████| 25/25 [00:12<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                Device                 Epoch               GPU Mem                  Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                     0                   3/4                 9.83G              0.007464: 100%|██████████| 25/25 [00:22<00:00,  1.12it/s]          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                Device               Correct              Accuracy                  Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                     0             1470/1566                0.9387              0.007765: 100%|██████████| 25/25 [00:12<00:00,  2.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                Device                 Epoch               GPU Mem                  Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                     0                   4/4                 9.83G               0.00778: 100%|██████████| 25/25 [00:22<00:00,  1.09it/s]          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                Device               Correct              Accuracy                  Loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                     0             1469/1566                0.9381              0.007758: 100%|██████████| 25/25 [00:11<00:00,  2.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "elaRfMd3Mog_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}